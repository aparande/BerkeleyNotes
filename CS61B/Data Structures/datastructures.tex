\documentclass{article}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{listings}
\usepackage{hyperref}
\begin{document}
    \title{CS61B -- Data Structures}
    \author{Anmol Parande}
    \date{Spring 2019 - Professor Josh Hug}
\maketitle
\tableofcontents
\textbf{Disclaimer: }These notes reflect 61B when I took the course (Spring 2019). They may not accurately reflect current course content, so use at your own risk.
If you find any typos, errors, etc, please report them on the \href{https://github.com/parandea17/BerkeleyNotes}{GitHub repository}.\\
\section{Lists}
\subsection{SLLists}
A Single-Linked-List is a one way Linked List (i.e each node keeps a reference to its successor)
\begin{lstlisting}[language=Java]
    class SLListNode<T> {
        T item;
        SLListNode next;
    }
\end{lstlisting}
To make the logic of methods in SLList easier, we often make the first node in an SLList a $\textbf{Sentinel Node}$.
The sentinel node contains a null item. If the SLList is empty, then \lstinline{sentinel.next = null}.
Otherwise, \lstinline{sentinel.next} is the first item of the SLList.
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c }
     Operation & Time Complexity\\
     \hline
     Size & $\Theta(1)$\\ 
     AddFront & $\Theta(1)$\\  
     AddLast & $\Theta(N)$\\
     DeleteFront & $\Theta(1)$\\
     DeleteLast & $\Theta(N)$\\
     Get & $\Theta(N)$
    \end{tabular}
\end{center}
\subsection{DLLists}
Since SLLists take long time to add to the front and to the back, a Double Linked List (DLList) can speed these up.
\begin{lstlisting}[language=Java]
    class DLListNode<T> {
        T item;
        DLListNode next;
        DLListNode prev;
    }
\end{lstlisting}
Like in SLLists, we can have a sentinel node to help us simplify operations.
\lstinline{sentinel.next} will be the first element in the list whereas \lstinline{sentinel.prev} is the last element of the list.
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c }
     Operation & Time Complexity\\
     \hline
     Size & $\Theta(1)$\\ 
     AddFront & $\Theta(1)$\\  
     AddLast & $\Theta(1)$\\
     DeleteFront & $\Theta(1)$\\
     DeleteLast & $\Theta(1)$\\
     Get & $\Theta(N)$
    \end{tabular}
\end{center}
\subsection{ArrayList}
LinkedLists are a poor choice for retrieving information inside of them unless we are only looking for the front or back element (or if the list is short).
For longer lists, we can make an array-based list called an ArrayList.
\begin{lstlisting}
    public class ArrayList<T> {
        T[] items
        public void resize(int N);
    }
\end{lstlisting}
An ArrayList simply maintains an array of all the items it has. The caveat is that when the array becomes full, we must resize it.
The way we resize the array affects its runtimes. If we increase the size of the array by a multiplicative factor (i.e doubling the array each time),
then the amortized (on average) runtime will still be constant.
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c }
     Operation & Time Complexity\\
     \hline
     Size & $\Theta(1)$\\ 
     AddFront & $\Theta(1)$\\  
     AddLast & $\Theta(1)$\\
     DeleteFront & $\Theta(1)$\\
     DeleteLast & $\Theta(1)$\\
     Get & $\Theta(1)$
    \end{tabular}
\end{center}
\section{Trees}
\subsection{Binary Search Tree}
In a Binary Search Tree, each node has a value, a left child, and a right child.
\begin{lstlisting}[language=Java]
public class Node<T> {
    T value;
    Node left;
    Node right;
}
\end{lstlisting}
\subsubsection{Invariants}
\begin{itemize}
    \item Every key in the left subtree is less than the root value
    \item Every key in the right subtree is greater than the root value
    \item No duplicates are in the BST
    \item The minimum element is the left most node
    \item The maximum element is the right most node
\end{itemize}
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c }
     Operation & Worst Case & Best Case\\
     \hline
     Height & $\Theta(N)$ & $\Theta(log N)$ \\ 
     Search & $\Theta(N)$ & $\Theta(log N)$ \\  
     Insert & $\Theta(N)$ & $\Theta(log N)$ \\
     Delete & $\Theta(N)$ & $\Theta(log N)$    
    \end{tabular}
\end{center}
The worst case runtime for a BST is when the tree is "spindly," meaning there are more nodes on either the right or left side (i.e, it is not "balanced")
\subsubsection{Hibbard Deletion}
Hibbard Deletion is a special method of efficient deletion.
You can either
\begin{itemize}
    \item[] Find the smallest key larger than the root value (called the successor) and make it root
    \item[OR ] 
    \item[] Find the largest key smaller than the root value (called the precessor) and make it root
\end{itemize}
\subsection{2-3, 2-3-4 Tree}
A 2-3-4 tree is the same idea as a BST, but it has extra operations to make it balanced.
Nodes in 2-3-4 tree's can be "stuffed", meaning they have more than 1 value inside them.
If a node is overstuffed, then it gives an item to the parent and splits the range of the children.
\subsubsection{Invariants}
\begin{itemize}
    \item All leaves are the same distance from the source
    \item Non-leaf with k items has exactly k+1 children
    \item The same invariants as BSTs
\end{itemize}
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c }
     Operation & Worst Case & Best Case\\
     \hline
     Height & $\Theta(log N)$ & $\Theta(log N)$ \\ 
     Search & $\Theta(log N)$ & $\Theta(log N)$ \\  
     Insert & $\Theta(log N)$ & $\Theta(log N)$  
    \end{tabular}
\end{center}
\subsection{Left Leaning Red Black Tree}
An LLRB is a BST but stays balanced using tree rotations. Each LLRB has a unique 2-3 tree because the red links represent stuffed nodes.
They are guaranteed to be balanced.
\subsubsection{Tree Rotations}
\begin{center}
    \begin{tabular}{ c c }
        Rotate Left & Rotate Right\\
        \begin{lstlisting}
            y = x.right
            x.right = y.left
            y.left = x
        \end{lstlisting} &
    \begin{lstlisting}
        y = x.left
        x.left = y.right
        y.right = x
    \end{lstlisting}
    \end{tabular}
\end{center}

\subsubsection{Inserting into a LLRB}
\begin{itemize}
    \item When inserting, use a red link
    \item If there are two consecutive red links, rotate the tree right
    \item If there is a right leaning 3-node, rotate the tree left
    \item If a node has two red children, color flip
\end{itemize}
\subsubsection{Invariants}
\begin{itemize}
    \item No node has two red links
    \item Every path to a leaf has the same number of black links
    \item There is a one-one correspondance to a 2-3 tree
\end{itemize}
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c }
     Operation & Worst Case & Best Case\\
     \hline
     Height & $\Theta(log N)$ & $\Theta(log N)$ \\ 
     Search & $\Theta(log N)$ & $\Theta(log N)$ \\  
     Insert & $\Theta(log N)$ & $\Theta(log N)$  
    \end{tabular}
\end{center}
\subsection{KD-Tree}
A KD-Tree is a multidimensional BTree. Each subsequent level splits on a different dimension of the data.
KD-Tree's are useful for finding the nearest point in the data to a given set of points.
\subsubsection{Invariants}
\begin{itemize}
    \item Each new level partitions data by a new dimension (nodes on the right are larger than root for that particular feature, vice versa for nodes on the left)
\end{itemize}
\section{Hashtables}
A Hashtable is simply an array of Linked Lists. Each node in the Linked list contains a value.
\subsection{Invariants}
\begin{itemize}
    \item Equal objects have equal hashcodes
    \item Objects which can change should not be stored
\end{itemize}
\subsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c | c }
     Operation & Worst Case & Best Case & Caveats\\
     \hline
     Contains & $\Theta(N)$ & $\Theta(N)$ & No Resize\\ 
     Add & $\Theta(N)$ & $\Theta(N)$ & No Resize \\  
     Contains & $\Theta(N)$ & $\Theta(1)$ & On Average \\
     Add & $\Theta(N)$ & $\Theta(1)$ & On Average
    \end{tabular}
\end{center}
The best case runtime occurs when we have a good hashcode (items are evenly distributed among buckets).
The worst case runtime occurs when we have a bad hashcode (items all fall into one bucket).
\section{Heaps}
A heap is made similar to a BST but with different invariants. They are useful in implementing priority queues.
\subsection{Invariants}
\begin{itemize}
    \item Complete: All nodes are as left as possible. Nodes are only missing from the bottom level
    \item Each node's value is less than the value of the children (in a min-heap, for a max-heap, it's the opposite)
\end{itemize}
\subsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c }
     Operation & Worst Case & Best Case\\
     \hline
     Add & $\Theta(log N)$ & $\Theta(1)$\\ 
     Get Smallest & $\Theta(1)$ & $\Theta(1)$\\  
     Remove Smallest & $\Theta(logN)$ & $\Theta(logN)$\\
    \end{tabular}
\end{center}
\textbf{Note:} These runtimes are amortized if the heap is represented as an array.
The true worst case runtime is $\theta(N)$ because of the resize operation.
\section{Tries}
A trie are like HashMaps except the nodes are Strings. They make prefixing operations very easy.
\subsection{Invariants}
\begin{itemize}
    \item Each node stores a single letter
    \item Nodes can be shared by many keys
    \item Nodes ending in keys are marked
\end{itemize}
\subsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c }
     Operation & Worst Case & Best Case\\
     \hline
     Get & $\Theta(1)$ & $\Theta(1)$\\ 
     Insert & $\Theta(1)$ & $\Theta(1)$\\  
    \end{tabular}
\end{center}
\section{Disjoint Sets}
A disjoint set has two operations, $connect$ and $isConnected$. Two items are connected if they are connected to the same item.
\subsection{QuickFind}
In QuickFind, the representation of the data is an array whose elements are the index of the group to which the object belongs.
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c }
     Operation & Worst Case & Best Case\\
     \hline
     Constructor & $\Theta(N)$ & $\Theta(N)$\\ 
     connect & $\Theta(N)$ & $\Theta(N)$\\  
     isConnected & $\Theta(1)$ & $\Theta(1)$\\
    \end{tabular}
\end{center}
\subsection{Quick Union}
In Quick Union, the representation of the data is an array whose elements are the parent of the item.
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c }
     Operation & Worst Case & Best Case\\
     \hline
     Constructor & $\Theta(N)$ & $\Theta(N)$\\ 
     connect & $\Theta(N)$ & $\Theta(1)$\\  
     isConnected & $\Theta(N)$ & $\Theta(1)$\\
    \end{tabular}
\end{center}
\subsection{Weighted Quick Union}
In Weighted Quick Union, the elements of the array are the parent of the item.
The difference from normal Quick Union is that when connecting two trees, the root of the smaller tree is linked to the root of the larger tree.
The root node will hold the number of children (the weight) as its element.
\subsubsection{Big-$\Theta$ Bounds}
\begin{center}
    \begin{tabular}{ c | c | c }
     Operation & Worst Case & Best Case\\
     \hline
     Constructor & $\Theta(N)$ & $\Theta(N)$\\ 
     connect & $\Theta(logN)$ & $\Theta(1)$\\  
     isConnected & $\Theta(logN)$ & $\Theta(logN)$\\
    \end{tabular}
\end{center}
\section{Graphs}
\begin{center}
    \begin{tabular}{ c | c | c | c | c}
     Representation & addEdge & print & hasEdge & Space\\
     \hline
     Adjacency Matrix & $\Theta(1)$ & $\Theta(V^2)$ & $\Theta(1)$ & $\Theta(V^2)$\\ 
     List of Edges & $\Theta(1)$ & $\Theta(E)$ & $\Theta(E)$ & $\Theta(E)$\\ 
     Adjacency List & $\Theta(1)$ & $\Theta(V + E)$ & $\Theta(ElogV)$ & $\Theta(E+V)$\\ 
    \end{tabular}
\end{center}
\end{document}
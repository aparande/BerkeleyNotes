# Nonlinear Feedback Control

In nonlinear control problems, we have a system

$$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}, \boldsymbol{u}).$$

$$\boldsymbol{x}$$ is the state of the system, and $$\boldsymbol{u}$$ is
the input to the system. Note that for simplicity, the system is
time-invariant. Further assume, without loss of generality, that
$$f(0, 0) = 0$$. The goal of nonlinear feedback control is to find a
state feedback law $$\alpha(\boldsymbol{x})$$ such that the equilibrium
point $$\boldsymbol{x}_e = 0$$ is globally asymptotically stable for the
closed loop system

$$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}, \alpha(\boldsymbol{x})).$$

Sometimes, the control impacts the state evolution in an affine manner.

{% hint style="info" %}

### Definition 52

A control affine system is given by the differential equation 

$$ \frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}) + G(\boldsymbol{x})\boldsymbol{u} $$

 where $$G(\boldsymbol{x})$$ is a matrix dependent on the state vector $$\boldsymbol{x}$$.

{% endhint %}

When designing controllers, there is a wide variety of techniques we can
use. Some simple techniques involve canceling out various types of
nonlinearities in the system using the input. Here are some examples.

1.  Set $$\boldsymbol{u}$$ such that it cancels out nonlinear terms and
    adds a stable linear term, effectively making the nonlinear system
    behave linear in the closed loop.

2.  Set $$\boldsymbol{u}$$ to cancel destabilitizing nonlinear terms and
    add a stable linear term, so the stable nonlinearities help the
    input drive the system to equilibrium.

3.  Set $$\boldsymbol{u}$$ to cancel destabilizing nonlinear terms, so
    the nonlinear system dynamics drive the system to equilibrium.

4.  Set $$\boldsymbol{u}$$ to dominate destabilizing terms so they have
    a minimal impact on the overall system behavior.

While these techniques can work, there are also more principled ways of
designing controllers to satisfy different criteria, particularly for
the case of control affine systems.

## Control Lyapunov Functions

If we can find an $$\alpha(\boldsymbol{x})$$ that makes the origin
globally asymptotically stable, then the converse Lyapunov theorem says
that we can find a corresponding Lyapunov function for the system.

$$\begin{aligned}     \forall \boldsymbol{x} \neq 0, \frac{d^{}V}{dt^{}} < 0 &\implies (\nabla_{\boldsymbol{x}}V)^\top f(\boldsymbol{x}, \alpha(\boldsymbol{x})) < 0 \\     &\implies \exists \boldsymbol{u} \text{ s.t } (\nabla_{\boldsymbol{x}}V)^\top f(\boldsymbol{x},     \boldsymbol{u}) < 0\\     & \Leftrightarrow \inf_{\boldsymbol{u}} (\nabla_{\boldsymbol{x}}V)^\top f(\boldsymbol{x}, \boldsymbol{u}) < 0\end{aligned}$$

This result motivates the following definition.

{% hint style="info" %}

### Definition 53

A continuously differentiable, PDF, radially unbounded $$V: \mathbb{R}^n \to \mathbb{R}$$ is a
Control Lyapunov Function for the system $$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}, \boldsymbol{u})$$ if 

$$ \forall \boldsymbol{x} \neq 0, \inf_{\boldsymbol{u}} (\nabla_{\boldsymbol{x}}V)^\top f(\boldsymbol{x}, \boldsymbol{u}) < 0 $$

{% endhint %}

Once we have a control lyapunov function, we can prove that it is
possible to find a state feedback law that will make the origin globally
asymptotically stable.

{% hint style="info" %}

### Theorem 27

Suppose $$f$$ is Lipschitz and $$V$$ is a control Lyapunov function, then there
exists a smooth function $$\alpha$$ such that the origin is a globally
asympototically stable equilibrium point of $$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}, \alpha(\boldsymbol{x}))$$.

{% endhint %}

Suppose that we have a control affine system, and we want to construct a
control lyapunov function for the system.

$$\inf_{\boldsymbol{u}} \frac{\partial V}{\partial \boldsymbol{x}}f(\boldsymbol{x}, \boldsymbol{u}) =     \inf_{\boldsymbol{u}} L_f V + \sum_i L_{g_i} V u_i < 0$$

Here, each $$g_i(\boldsymbol{x})$$ is a column of $$G(\boldsymbol{x})$$.
If $$\forall i,\ L_{g_i} V = 0$$, then Definition 53 is satisfied so
long as $$L_f V < 0$$.

{% hint style="info" %}

### Theorem 28

A function $$V$$ is a control lyapunov function for a control affine system 

$$ \frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}) + \sum_i g_i(\boldsymbol{x}) u_i $$

 if 

$$ L_{g_i} V\, \forall i \implies L_f V \leq 0 $$

{% endhint %}

Notice that the condition in Theorem 28 is essentially saying that the
$$l_2$$-norm of the vector composed of the $$L_{g_i} V$$ is equal to 0.
The choice of CLF is important because different CLFs have different
properties when used to derive controllers.

{% hint style="info" %}

### Definition 54

A CLF $$V(\boldsymbol{x})$$ satisfies the small control property if $$\forall \epsilon > 0$$, $$\exists \delta > 0$$ such that $$\boldsymbol{x}\in B_\delta(0)$$, then if
$$\boldsymbol{x}\neq0, \exists \boldsymbol{u}\in B_\epsilon(0)$$ satisfying 

$$ \frac{d^{}V}{dt^{}} = L_fV + L_GV^T\boldsymbol{u} < 0. $$

{% endhint %}

The small control property means that CLF will lead to a controller
which has a small value that does not get too large when close to the
equilibrium.

Given a control lyapunov function for a control affine system
$$V(\boldsymbol{x}, \boldsymbol{u})$$, we can devise a controller which
stabilizes the system. In particular, we need

$$\frac{dV}{dt}(x, u) = L_f V(\boldsymbol{x}) + L_GV(\boldsymbol{x})^\top \boldsymbol{u} \leq 0.$$

Hence, let

$$\boldsymbol{u} = \begin{cases}         0, & \text{if } L_f V < 0,\\         (L_GVL_GV^\top)^{-1}(-L_fV L_GV^\top), & \text{if } L_f V > 0.     \end{cases}$$

When the plant dynamics are naturally stabilizing, this controller
exerts no control effort. When the plant dynamics are not naturally
stabilizing, then the controller applies some control to stabilize the
system. We can show that this is a minimum norm controller as it solves
the optimization problem

$$\begin{aligned}         \min &\quad \boldsymbol{u}^\top \boldsymbol{u}\\         \text{s.t} &\quad L_fV + L_GV^\top \boldsymbol{u} \leq 0.     \end{aligned}$$

Another type of controller is known as the Sontag controller.

{% hint style="info" %}

### Theorem 29

Suppose $$V:\mathbb{R}^n\to\mathbb{R}$$ is a CLF for SISO control affine system $$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}) + g(\boldsymbol{x})u$$ where $$f(0) = 0$$ where $$f$$ and $$g$$ are Lipschitz. Then
the Sontag feedback control law is given by 

$$ \alpha_S(\boldsymbol{x}) = \begin{cases} \frac{-L_fV - \sqrt{(L_fV)^2 + (L_gV)^4}}{L_gV}, & \text{if } L_gV \neq 0,\\ 0, & \text{else.} \end{cases} $$


makes the origin globally asymptotically stable. Moreover,
$$\alpha_S(\boldsymbol{x})$$ is continuous everywhere except $$\boldsymbol{x} = 0$$, is
continuous at $$\boldsymbol{x}=0$$ if $$V$$ satisfies the small control property, and if
$$V(\boldsymbol{x})$$ is $$K+1$$ times continuously differentiable and $$f(\boldsymbol{x}), g(\boldsymbol{x})$$ are $$K$$ times continously differentiable $$\forall \boldsymbol{x}\neq0$$,
then $$\alpha_S$$ is $$K$$times continuously differentiable.

{% endhint %}

## Feedback Linearization

Since we have a large number of tools which allow us to control linear
systems, it would be ideal if we could somehow leverage those tools for
nonlinear control. Feedback linearization is the process of finding a
feedback control law $$\boldsymbol{u} = \alpha(\boldsymbol{x})$$ such
that under a nonlinear change of coordinates
$$z = \Phi(\boldsymbol{x})$$, the system
$$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}, \alpha(\boldsymbol{x}))$$
behaves like a linear system
$$\frac{d^{}\boldsymbol{z}}{dt^{}} = A\boldsymbol{z}$$. When the system
is control-affine, there are well-established results which help us do
this.

### SISO Case

Suppose we have a SISO control-affine system

$$\begin{aligned}         \frac{d^{}\boldsymbol{x}}{dt^{}} &= f(\boldsymbol{x}) + g(\boldsymbol{x})u\\         y &= h(\boldsymbol{x})     \end{aligned}$$

{% hint style="info" %}

### Definition 55

A SISO control affine system with an equilibrium point $$\boldsymbol{x}_e$$ has
strict relative degree $$\gamma$$ if in a neighborhood $$U$$ around the
equilibirum point, $$L_gL_f^{\gamma-1}h(\boldsymbol{x})$$ is bounded away from 0 and 

$$ \forall i=0,\cdots,\gamma-2,\ L_gL_f^{\gamma - 1}h(\boldsymbol{x}) = 0 $$

{% endhint %}

To understand relative degree, suppose we differentiate $$y$$ once

$$\frac{d^{}y}{dt^{}} = L_fh + L_gh u.$$

If $$\forall \boldsymbol{x}\in U,\ L_gh(\boldsymbol{x}) = 0$$ where
$$U$$ is some region around the equilibrium, then

$$\forall \boldsymbol{x}\in U,\ \frac{d^{}y}{dt^{}} = L_fh(\boldsymbol{x}).$$

If we differentiate again, then

$$\forall \boldsymbol{x}\in U,\ \frac{d^{2}y}{dt^{2}} = L_f^2h(\boldsymbol{x}) + L_gL_fh(\boldsymbol{x}).$$

Suppose that
$$\forall \boldsymbol{x}\in U,\ L_gL_fh(\boldsymbol{x}) = 0$$, then we
can differentiate again. At some point, after $$\gamma$$
differentiations, we will get

$$\forall \boldsymbol{x}\in U,\ \frac{d^{\gamma}y}{dt^{\gamma}} = L_f^\gamma h(\boldsymbol{x}) +     L_gL_f^{\gamma-1}h(\boldsymbol{x})u.$$

Therefore, the relative degree of the system is essentially telling us
which derivative of the output that we can control. By sequentially
taking derivatives, we are essentially looking at the system

$$\begin{aligned}         y &= h(\boldsymbol{x})\\         \frac{d^{}y}{dt^{}} &= L_fh(\boldsymbol{x})\\         \frac{d^{2}y}{dt^{2}} &= L_f^2h(\boldsymbol{x})\\         &\vdots\\         \frac{d^{\gamma}y}{dt^{\gamma}} &= L_f^\gamma h(\boldsymbol{x}) + L_gL_f^{\gamma-1}h(\boldsymbol{x})     \end{aligned}$$

Suppose $$\forall i=0,\cdots,\gamma-1,$$ we let
$$\xi_i(\boldsymbol{x}) = \frac{d^{i}y}{dt^{i}}$$. These are $$\gamma$$
linearly independent coordinates. Since the distribution

$$\Delta(\boldsymbol{x}) = \text{span}\{g(\boldsymbol{x})\}$$

is involutive, it is integrable, and so there must be $$n-1$$ functions
$$\eta_i$$ such that

$$\forall \boldsymbol{x}\in U,\ (\nabla_{\boldsymbol{x}}\eta_i)^\top g(\boldsymbol{x}) = 0.$$

We can now choose $$n-\gamma$$ of them which are linearly independent of
the $$\xi_i$$ and linearly independent with each other, and this forms a
change of coordinates

$$\begin{bmatrix}         \xi_1\\         \vdots\\         \xi_{\gamma}\\         \eta_1\\         \vdots\\         \eta_{n-\gamma}     \end{bmatrix} = \Phi(\boldsymbol{x}) = \begin{bmatrix}         h(\boldsymbol{x})\\         L_fh(\boldsymbol{x})\\         \vdots\\         L_f^{\gamma-1}\\         \eta_1\\         \vdots\\         \eta_{n-\gamma}     \end{bmatrix}.$$

This change of coordinates allows us to put the system into a canonical
form.

{% hint style="info" %}

### Definition 56

The normal form of a SISO control affine system is given by 

$$ \begin{aligned} \frac{d^{}\xi_1}{dt^{}} &= \xi_2\\ \frac{d^{}\xi_2}{dt^{}} &= \xi_3\\ &\vdots\\ \frac{d^{}\xi_{\gamma}}{dt^{}} &= b(\boldsymbol{\xi}, \boldsymbol{\eta}) + a(\boldsymbol{\eta}, \boldsymbol{\xi})u\\ \frac{d^{}\boldsymbol{\eta}}{dt^{}} &= q(\boldsymbol{\xi}, \boldsymbol{\eta}),\\ y &= \eta_1 \end{aligned} $$

{% endhint %}

When the original system is given by
$$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x})+g(\boldsymbol{x})u$$,
then

$$b(\boldsymbol{\xi},\boldsymbol{\eta}) = L_f^\gamma h(\Phi^{-1}(\boldsymbol{\xi}, \boldsymbol{\eta})) \qquad     a(\boldsymbol{\xi}, \boldsymbol{\eta}) = L_gL_f^{\gamma-1} h(\Phi^{-1}(\boldsymbol{\xi}, \boldsymbol{\eta}))$$

With this parameterization, it is quite easy to see how we can make our
system behave linearly. In particular, choose

$$u = \frac{1}{a(\boldsymbol{\xi}, \boldsymbol{\eta})}\left(-b(\boldsymbol{\xi}, \boldsymbol{\eta}) +     v\right)$$

where $$v$$ is some control input. Then the system becomes

$$\begin{aligned}         \frac{d^{}\xi_1}{dt^{}} &= \xi_2\\         \frac{d^{}\xi_2}{dt^{}} &= \xi_3\\         &\vdots\\         \frac{d^{}\xi_{\gamma}}{dt^{}} &= v\\         \frac{d^{}\boldsymbol{\eta}}{dt^{}} &= q(\boldsymbol{\xi}, \boldsymbol{\eta})\\         y &= \eta_1     \end{aligned}$$

, which is a linear system. Therefore, we can design a linear feedback
controller $$v = \alpha(\boldsymbol{x})$$ where we have all of the tools
of linear control at our disposal. However, notice that the $$\eta_i$$
cannot be impacted by the control effort. These are known as the
**internal dynamics** of the system. When $$\boldsymbol{\xi} = 0$$, then

$$\frac{d^{}\boldsymbol{\eta}}{dt^{}} = q(0, \boldsymbol{\eta})$$

are known as the **Zero Dynamics** of the system. Zero dynamics for a
system can be dangerous because if they are unstable, then the system
could be blowing up. When $$\gamma = n$$, then there are no zero
dynamics. When this happens, we say the system is **Full State
Linearizable**. Fortunately, there are necessary and sufficient
conditions which guarantee full state linearization.

{% hint style="info" %}

### Theorem 30

There exists a function $$h$$ such that a control affine system
$$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}) + g(\boldsymbol{x})u$$ has relative degree $$n$$ at
$$\boldsymbol{x}_0$$ if and only if 

$$ \begin{bmatrix} g(\boldsymbol{x}) & \cdots & \text{ad}_f^{n-2}g(\boldsymbol{x}) & \text{ad}_f^{n-1}g(\boldsymbol{x}) \end{bmatrix} $$


has rank $$n$$ and 

$$ \begin{bmatrix} g(\boldsymbol{x}) & \cdots & \text{ad}_f^{n-3}g(\boldsymbol{x}) & \text{ad}_f^{n-2}g(\boldsymbol{x}) \end{bmatrix} $$


has rank $$n-1$$ and is involutive in the neighborhood of $$\boldsymbol{x}_0$$. The $$h$$ is
chosen to satisfy 

$$ (\nabla_{\boldsymbol{x}}h)^\top \begin{bmatrix} g(\boldsymbol{x}) & \cdots & \text{ad}_f^{n-3}g(\boldsymbol{x}) & \text{ad}_f^{n-2}g(\boldsymbol{x}) \end{bmatrix} = 0 $$

{% endhint %}

### MIMO Case

Suppose instead we have a MIMO control affine system where

$$\begin{aligned}         \frac{d^{}\boldsymbol{x}}{dt^{}} &= f(\boldsymbol{x}) + G(\boldsymbol{x})\boldsymbol{u}\\         \boldsymbol{y} &= h(\boldsymbol{x})     \end{aligned}$$

We will assume that the number of outputs is equal to the number of
inputs (i.e $$\boldsymbol{y}, \boldsymbol{u} \in \mathbb{R}^m$$). To
linearize the system, we can take the same idea of relative degree from
the SISO case and apply it to the MIMO case. Define $$\gamma_j$$ to be
the lowest derivative of $$y_j$$ which is impacted by at least one
input.

$$\begin{bmatrix}         \frac{d^{\gamma_1}y_1}{dt^{\gamma_1}}\\         \vdots\\         \frac{d^{\gamma_m}y_m}{dt^{\gamma_m}}     \end{bmatrix}     = \begin{bmatrix}         L_f^{\gamma_1}h_1(\boldsymbol{x})\\         \vdots\\         L_f^{\gamma_m}h_m(\boldsymbol{x})\\     \end{bmatrix} + A(\boldsymbol{x})\boldsymbol{u}, \qquad A(\boldsymbol{x}) = \begin{bmatrix}         L_{g_1}L_f^{\gamma_1-1}h_1(\boldsymbol{x}) & \cdots &         L_{g_m}L_f^{\gamma_1-1}h_1(\boldsymbol{x})\\         \vdots & \ddots & \vdots\\         L_{g_1}L_f^{\gamma_m-1}h_m(\boldsymbol{x}) & \cdots &         L_{g_m}L_f^{\gamma_m-1}h_m(\boldsymbol{x})     \end{bmatrix}$$

{% hint style="info" %}

### Definition 57

A square control affine system has a vector relative degree $$(\gamma_1, \cdots, \gamma_m)$$ at $$\boldsymbol{x}_0\in U$$ if $$A(\boldsymbol{x}_0)$$ is nonsingular and 

$$ \forall 1\leq i\leq m,\ 1\leq j \leq m,\ 0 \leq k \leq \gamma_j-2,\ \forall \boldsymbol{x}\in U,\ L_{g_i}L_f^kh_j(\boldsymbol{x}) = 0 $$

\\label{thm:vector-relative-degree}

{% endhint %}

As before, we can assign $$\frac{d^{i}y_j}{dt^{i}} = \xi_i^j$$ as a
partial change of coordinates and then choose linearly independent
$$\boldsymbol{\eta}$$.

{% hint style="info" %}

### Definition 58

The normal form of a square MIMO system is given by


$$ \begin{aligned} \frac{d^{}\boldsymbol{\eta}}{dt^{}} &= q(\boldsymbol{\xi},\boldsymbol{\eta}) + p(\boldsymbol{\xi}, \boldsymbol{\eta})\boldsymbol{u}\\ \frac{d^{}\xi_i^j}{dt^{}} &= \xi_{i+1}^j, &\quad \forall j,\ \forall i < \gamma_j-1\\ \frac{d^{}\xi_{\gamma_j-1}^j}{dt^{}} &= b^j(\boldsymbol{\xi},\boldsymbol{\eta}) + \boldsymbol{a}^j(\boldsymbol{\xi},\boldsymbol{\eta})^\top\boldsymbol{u} \end{aligned} $$

{% endhint %}

As before the $$\frac{d^{}\boldsymbol{\eta}}{dt^{}}$$ represent the
internal dynamics of the system that are not impacted by the control. As
with the linear case, we can design a controller

$$\boldsymbol{u} = A^{-1}(\boldsymbol{x})\left(     \begin{bmatrix}         L_f^{\gamma_1}h_1(\boldsymbol{x})\\         \vdots\\         L_f^{\gamma_m}h_m(\boldsymbol{x})\\     \end{bmatrix} + \boldsymbol{v}\right)$$

which renders the system linear. We can now choose $$\boldsymbol{v}$$
where each entry of $$\boldsymbol{v}$$ controls a different output. For
this reason, we call $$A(\boldsymbol{x})$$ the decoupling matrix. As in
the SISO case, unless $$\sum_j \gamma_j = n$$, there are zero dynamics
to the system.

{% hint style="info" %}

### Theorem 31

A control affine square system $$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x}) + G(\boldsymbol{x})\boldsymbol{u}$$ has vector relative degree $$\sum_j \gamma_j = n$$ if and only
if $$\Delta_i$$ is involutive for all $$i \leq n-2$$, $$\Delta_i$$ has constant rank
for all $$1 \leq i \leq n-1$$ and $$\Delta_{n-1}$$ has rank $$n$$ where 

$$ \begin{aligned} \Delta_0(\boldsymbol{x}) &= \text{span}\{g_1(\boldsymbol{x}),\cdots,g_m(\boldsymbol{x})\}\\ \Delta_i(\boldsymbol{x}) &= \text{span}\{\text{ad}_f^kg_i(\boldsymbol{x})\ |\  \forall 0 \leq k \leq i, 1 \leq j \leq m\}, &\quad \forall 1 \leq i \leq n-1 \end{aligned} $$

{% endhint %}

### Dynamic Extension

Sometimes, we can use full-state linearization even if $$h$$ does not
satisfy the conditions in Theorem 30. We do this by adding additional
states to the system and corresponding pseudo-control inputs which help
control these states. Sometimes, this can be done in a way which makes
the extended system full-state linearizable.

### Sliding Mode Control

In sliding mode control, we design a controller

$$u = \beta(\boldsymbol{x})\text{sgn}(s)$$

where $$s(\boldsymbol{x})$$ describes a manifold called the “sliding
manifold”. Sliding mode controllers have two states

1.  Reaching Mode

2.  Sliding Mode

During the reaching mode, the controller drives the state towards the
sliding manifold $$s(\boldsymbol{x}) = 0$$. We choose $$s$$ such that on
the manifold, when the system is in sliding mode, the system naturally
converges asymptotically to the equilibrium. If
$$s(\boldsymbol{x}) = 0$$ is an invariant manifold, then the system will
smoothly travel along the manifold to equilibrium. If the sliding
manifold is not invariant, then the state will chatter around the
manifold towards equilibrium as the controller continuously drives it
back to the manifold once it leaves. To choose $$s$$, we need to find a
CLF $$V(s)$$ which converges to $$0$$ in finite time when applying the
sliding mode controller.

### Backstepping

{% hint style="info" %}

### Definition 59

A system expressed in strict feedback form is given by 

$$ \begin{aligned} \frac{d^{}\boldsymbol{x}}{dt^{}} &= f_0(\boldsymbol{x}) + g_0(\boldsymbol{x})\xi_1\\ \frac{d^{}\xi_1}{dt^{}} &= f_1(\boldsymbol{x}, \xi_1) + g_1(\boldsymbol{x}, \xi_1)\xi_2\\ &\vdots\\ \frac{d^{}\xi_k}{dt^{}} &= f_k(\boldsymbol{x}, \xi_1,\cdots,\xi_k) + g_k(\boldsymbol{x}, \xi_1,\cdots,\xi_k)u\\ \end{aligned} $$

{% endhint %}

When systems are expressed in this way, we have a convenient method of
designing controllers.

{% hint style="info" %}

### Theorem 32 (Backstepping Lemma) {#theorem-32}

Suppose there is a continuously differentiable $$u=\alpha(\boldsymbol{x})$$ and a CLF
$$V(\boldsymbol{x})$$ such that 

$$ L_fV + L_gV\alpha \leq -W $$

 where $$W$$ is a positive semi-definite function for the system
$$\frac{d^{}\boldsymbol{x}}{dt^{}} = f(\boldsymbol{x})+g(\boldsymbol{x})u$$. Then for the system 

$$ \begin{aligned} \frac{d^{}\boldsymbol{x}}{dt^{}} &= f(\boldsymbol{x}) + g(\boldsymbol{x})\xi\\ \frac{d^{}\xi}{dt^{}} &= u \end{aligned} $$


the function 

$$ V_a(\boldsymbol{x},\xi) = V(\boldsymbol{x}) + \frac{1}{2}(\xi - \alpha(\boldsymbol{x}))^2 $$

 is a valid CLF and the control input 

$$ u = -c(\xi-\alpha(\boldsymbol{x})) + (\nabla_{\boldsymbol{x}}\alpha)^\top(f(\boldsymbol{x}) + g(\boldsymbol{x})\xi) - (\nabla_{\boldsymbol{x}}V)^\top g(\boldsymbol{x}), \qquad c > 0 $$

is a stabilizing controller.

{% endhint %}

If we apply Theorem 32 to a system expressed in strict feedback form,
then we can recursively define controllers until we arrive at a
controller for the full system.

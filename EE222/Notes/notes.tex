\input{../../header.tex}
\begin{document}
\title{EE222 Course Notes}
\author{Anmol Parande}
\date{Spring 2022 - Professors Shankar Shastry and Koushil Srinath}
\maketitle
\textbf{Disclaimer: }These notes reflect EE222 when I took the course (Fall 2021). They may not accurately reflect current course content, so use at your own risk.
If you find any typos, errors, etc, please raise an issue on the \href{https://github.com/parandea17/BerkeleyNotes}{GitHub repository}.
\tableofcontents
\newpage
\section{Real Analysis}
\begin{definition}
	The extended real line is the set \[
		\{-\infty\} \cup \R \cup \{\infty\}
	\]
	\label{defn:extended-real-line}
\end{definition}
\begin{definition}
	The supremum of a set $S \subset \R$ is a value $a \in \R_e$
	such that $\forall s\in S,\ s \leq a$ and if $b \in \R_e$ such that
	$\forall s\in S,\ s \leq b$, then $a \leq b$.
	\label{defn:supremum}
\end{definition}
Supremum is essentially the ``least upper bound'' in a set. It always exists,
and is called $\sup S$. The opposite of supremum is the infinimum.
\begin{definition}
	The infinimum of a set $S \subset \R$ is a value $a \in \R_e$
	such that $\forall s\in S,\ s \geq a$ and if $b \in \R_e$ such that
	$\forall s\in S,\ s \geq b$, then $a \geq b$.
	\label{defn:infinimum}
\end{definition}
The infinimum is the ``greatest upper bound''. Like the supremum, it always
exists, and it is denoted $\inf S$. Supremum and Infinimum can be applied to
scalar function $f: S\to \R$ by letting \[
	\sup_{x\in S} f(x) = \sup \{f(x) | x\in S \}.
\]
\subsection{Norms}
\begin{definition}
	Let $V$ be a vector space of $\R$, then $\|\cdot\|: V \to \R$ is a norm if
	$\forall \bs{x},\bs{y}\in V, \alpha \in \R$, \[
		\|\bs{x}\| \geq 0 \qquad \bs{x} = 0 \Leftrightarrow \|\bs{x}\| = 0 \qquad
		\|\alpha \bs{x}\| = |\alpha|\|\bs{x}\| \qquad \|\bs{x} + \bs{y}\| \leq
		\|\bs{x}\| + \|\bs{y}\|
	\]
	\label{defn:norm}
\end{definition}
\begin{definition}
	A normed space $(V, \|\cdot\|)$ is a vector space which is equipped with a
	norm $\|\cdot\|: V \to \R$.
	\label{defn:normed-space}
\end{definition}
If we have an operator $A$ which takes as inputs vectors from normed space $(X,
\|\cdot\|_X)$ and outputs vectors in normed space $(Y, \|\cdot\|_Y)$, then we
can define another norm on the vector space of operators from $X\to Y$.
\begin{definition}
	Let $A:X\to Y$ be an operator between normed spaces $(X, \|\cdot\|_X)$ and
	$(Y, \|\cdot\|_Y)$, then the induced norm of $A$ is \[
		\|A\|_i = \sup_{\|\bs{x} \neq 0\|_X} \frac{\|A\bs{x}\|_Y}{\|\bs{x}\|_X}
	\]
	\label{defn:induced-norm}
\end{definition}
The induced norm can be thought of as the maximum gain of the operator.
\begin{definition}
	Two norms $\|\cdot\|$ and $|||\cdot|||$ on a vector space $V$ if $\exists k_1,
	k_2 > 0$ suh that \[
		\forall \bs{x}\in V,\ k_1\|\bs{x}\| \leq |||\bs{x}||| \leq k_2\|\bs{x}\|
	\]
	\label{defn:equivalent-norm}
\end{definition}
If $V$ is a finite dimensional vector space if and only if all norms of $V$ are
equivalent.

\subsection{Sets}
\begin{definition}
	Let $(V, \|\cdot\|)$ be a normed space, $a\in \R$, $a > 0$, $\bs{x}_0\in V$,
	then the open ball of radius $a$ centered around $x_0$ is given by \[
		B_a(\bs{x}_0) = \{ \bs{x} \in V \ | \ \|\bs{x} - \bs{x}_0\| < a \}
	\]
	\label{defn:open-ball}
\end{definition}
\begin{definition}
	A set $S\subset V$ is open if $\forall \bs{s}_0\in V,\ \exists \epsilon > 0$
	such that $B_\epsilon(\bs{s}_0) \subset S$.
	\label{defn:open-set}
\end{definition}
Open sets have a boundary which is not included in the set. By convention, we
say that the empty set is open.

The opposite of an open set is a closed set.
\begin{definition}
	A set $S$ is closed if $\sim S$ is open.
	\label{defn:closed-set}
\end{definition}
Closed sets have a boundary which is included in the set.

\subsection{Convergence}
\begin{definition}
	A sequence of points $\bs{x}_k$ in normed space $(V, \|\cdot\|)$ converges to
	a point $\bar{\bs{x}}$ if \[
		\forall \epsilon > 0,\ \exists N < \infty,\ \text{ such that } \forall k
		\geq N, \|\bs{x}_k - \bar{\bs{x}}\| < \epsilon
	\]
	\label{defn:convergence}
\end{definition}
Convergence means that we can always find a finite time such that after that
time, all points in the sequence stay within a specicied norm ball.
\begin{definition}
	A sequence $\bs{x}_k$ is cauchy if \[
		\forall \epsilon > 0,\ \exists N < \infty \text{ such that } \forall n,m
		\geq N, \|\bs{x}_m - \bs{x}_n\| < \epsilon
	\]
	\label{defn:cauchy-sequence}
\end{definition}
A Cauchy sequence has a looser type of convergence than a convergent sequence
since it only requires all elements to in the sequence to be part of the same
norm ball after some time instead of requiring the sequence to get closed and
closer to a single point.
\begin{theorem}
	If $\bs{x}_n$ is a convergent sequence, then $\bs{x}_n$ is a also a Cauchy
	sequence.
	\label{thm:cauchy-convergence}
\end{theorem}
\begin{definition}
	A normed space $(V, \|\cdot\|)$ is complete if every Cauchy sequence converges
	to a point in $V$
	\label{defn:complete-space}
\end{definition}
Because a complete space requires that Cauchy sequences converge, all cauchy
sequences are convergent in a complete space. Two important complete spaces are
\begin{enumerate}
	\item Every finite dimensional vector space
	\item $(C[a,b], \|\cdot\|_\infty)$, the set of continuously differentiable
		functions on the closed interval $[a,b]$ equipped with the infinity norm.
\end{enumerate}
A complete normed space is also called a \textbf{Banach Space}.

\subsection{Contractions}
\begin{definition}
	A point $x^*$ is a fixed point of a function $P:X\to X$ if $P(x^*)=x^*$.
	\label{defn:fixed-point}
\end{definition}
\begin{definition}
	A function $P:X\to X$ is a contract if there exists a constant $0\leq c < 1$
	such that \[
		\forall \bs{x},\bs{y}\in X,\ \|P(\bs{x}) - P(\bs{y})\| \leq c
		\|\bs{x}-\bs{y}\|
	\]
	\label{defn:contraction}
\end{definition}
Informally, a contraction is a function which makes distances smaller 

Suppose we look at a sequence defined by iterates of a function \[
	\bs{x}_{k+1} = P(\bs{x}_k).
\]
where $P$ is a function $P:X\to X$. When does this sequence converge, and to
what point will it converge?
\begin{theorem}[Contraction Mapping Theorem]
	If $P:X\to X$ is a contraction on the Banach space $(X, \|\cdot\|)$, then
	there is a unique $\bs{x}^*\in X$ such that $P(\bs{x}^*) = \bs{x}^*$ and
	$\forall x_0\in X$, the sequence $\bs{x}_{n+1} = P(\bs{x}_n)$ is converges to
	$\bs{x}^*$.
	\label{thm:contraction-mapping}
\end{theorem}
The contraction mapping theorem that contractions will have a unique fixed
points and that repeatedly applying the contraction will converge to the fixed
point.

\subsection{Continuity}
\begin{definition}
	A function $h:V\to W$ on normed spaces $(V, \|\cdot\|_V)$ and $(W,
	\|\cdot\|_W)$ is continuous at a point $\bs{x}_0$ if $\forall \epsilon > 0,
	\exists \delta > 0$ such that \[
		\|\bs{x}-\bs{x}_0\|_V < \delta \implies \|h(\bs{x}) - h(\bs{x_0})\|_W < \epsilon
	\]
	\label{thm:continuity}
\end{definition}
Continuity essentially means that given an $\epsilon-$ball in $W$, we can find a
$\delta-$ball in $V$ which is mapped to the ball in $W$.
If a function is continuous at all points $\bs{x}_0$, then we say the function
is continuous.

We can make the definition of continuity more restrictive by restraining the
rate of growth of the function.
\begin{definition}
	A function $h:V\to W$ on normed spaces $(V, \|\cdot\|_V)$ and $(W,
	\|\cdot\|_W)$ is Lipschitz continuous at $\bs{x}_0\in V$ if $\exists r > 0$
	and $L < \infty$ such that \[
		\forall \bs{x}, \bs{y}\in B_r(\bs{x}_0),\ \|h(\bs{x}) - h(\bs{y})\|_W \leq L
		\|\bs{x} - \bs{y}\|_V
	\]
	\label{defn:lipschitz-continuity}
\end{definition}
A good interpretation of Lipschitz Continuity is that given two points in a ball
around $\bs{x}_0$, the slope of the line connecting those two points is less
than $L$. It means that the function is growings slower than linear for some
region around $\bs{x}_0$. Lipschitz continuity implies continuity. If a function
is lipschitz continuous with respect to one norm, it is also lipschitz
continuous with respect to all equivalent norms.

When the function $h$ is a function on $\R^n$ and is also
differentiable, then Lipschitz continuity is easy to determine.
\begin{theorem}
	For a differentiable function $h:\R^n\to\R^n$, \[
		\exists r>0, L < \infty, \bs{x}_0\in\R^n,\ \forall \bs{x}\in B_r(\bs{x}),
		\left\lvert\left\lvert\frac{\partial h}{\partial
		\bs{x}}\right\rvert\right\rvert_2 \leq L
	\] implies Lipschitz Continuity at $\bs{x}_0$.
	\label{thm:differentiable-lipschitz}
\end{theorem}
\begin{definition}
	A function $h:\R\to V$ is piecewise continuous if $\forall k\in \mathbb{Z}$,
	$h:[-k, k] \to V$ is continuous except at a possibly finite number of points,
	and at the points of discontinuity $t_i$, $\lim_{s\to0^+} h(t_i+s)$ and
	$\lim_{s\to0^-}$ exist and are finite. 
	\label{defn:piecewise-continuous}
\end{definition}
\section{Nonlinear System Dynamics}
Consider the non-linear system \[
	\diff[]{\bs{x}}{t} = f(\bs{x}, t).
\]
\begin{definition}
	The system is autonomous if $f(x, t)$ is not explicitly dependent on time $t$.
	\label{defn:autonomous-system}
\end{definition}
\begin{definition}
	A point $x_0$ is an equilibrium point at time $t_0$ if \[
		\forall t \geq t_0, \ f(x_0, t) = 0 
	\]
	\label{defn:equilibrium-point}
\end{definition}
Consider a single trajectory $\bs{x}(t, t_0, \bs{x}_0)$.
\begin{definition}
	A set $S$ is said to be the $\omega-$limit set of $\phi$ if\[
		\forall y\in S,\exists t_n\to \infty, \lim_{n\to\infty}\phi(t_n, t_0,
		\bs{x}_0) = y
	\]
	\label{defn:w-limit-set}
\end{definition}
Whereas linear systems converge to a single point if they converge at all,
nonlinear systems can converge to a set of points. Thus the $\omega-$limit set
essentially generalizes the idea of a limit.
\begin{definition}
	A set $M\subset \R^n$ is said to be invariant if \[
		\forall t\geq t_0,\ \bs{y}\in M \implies \phi(t, t_0, \bs{y}) \in M
	\]
	\label{defn:invariant-set}
\end{definition}
An invariant set is one which a trajectory of the system will never leave once it enters the
set.
\subsection{Solutions to Nonlinear Systems}
Consider the nonlinear system \[
	\diff[]{\bs{x}}{t} = f(\bs{x}, t),\ \bs{x}(t_0) = \bs{x}_0\in \R^n.
\]
\begin{definition}
	A function $\bs{\Phi}(t)$ is a solution to $\diff[]{\bs{x}}{t} = f(x, t),\
	\bs{x}(t_0) = \bs{x}_0$ on the closed interval $[t_0, t]$ if $\bs{\Phi}(t)$
	is defined on the interval $[t_0, t]$, $\diff[]{\bs{\Phi}}{t} =
	f(\bs{\Phi}(t), t)$ on the interval $[t_0, t]$, and $\bs{\Phi}(t_0) =
	\bs{x}_0$.
	\label{defn:nonlinear-solution}
\end{definition}
We say that $\Phi(t)$ is a solution in the sense of Caratheodory if \[
	\Phi(t) = \bs{x}_0 + \int_{t_0}^t f(\bs{\Phi}(\tau), \tau)d\tau.
\]
Because the sytem is non-linear, it could potentially have no solution, one
solution, or many solutions. These solutions could exist locally, or they could
exist for all time. We might also want to know when there is a solution which
depends continuously on the initial conditions.
\begin{theorem}[Local Existence and Uniqueness]
	Given $\diff{\bs{x}}{t} = f(\bs{x}, t),\ \bs{x}(t_0) = \bs{x}_0\in\R^n$ where
	$f$ is piecewise continuous in $t$ and $\exists T>t_0$ such that $\forall t\in
	[t_0, T], f$ is $L$-Lipschitz Continuous, then $\exists \delta > 0$ such that a
	solution exists and is unique $\forall t\in [t_0, t_0 + \delta]$.
	\label{thm:local-existence}
\end{theorem}
\Cref{thm:local-existence} can be proved using the Contraction Mapping Theorem
(\cref{thm:contraction-mapping}) by finding $\delta$ such that the function
$P:C_n[t_0, t_0+\delta] \to C_n[t_0, t_0+\delta]$ given by \[
	P(\bs{\Phi})(t) = \bs{x}_0 + \int_{t_0}^{t_0+\delta} f(\bs{\Phi}(\tau),
	\tau)d\tau
\]
is a contraction under the norm $\|\bs{\Phi}\|_\infty = \sup_{t_0\leq t \leq
t_0+\delta} \|\bs{\Phi}(t)\|$.
\begin{theorem}[Global Existence and Uniqueness]
	Suppose $f(\bs{x}, t)$ is piecewise continuous in $t$ and $\forall T\in [t_0,
	\infty)$, $\exists L_T < \infty$ such that $f$ is $L_T$ Lipshitz continuous
	for all $\bs{x}, \bs{y} \in \R^n$, then the nonlinear system  has exactly one
	solution on $[t_0, T]$.
	\label{thm:global-existence}
\end{theorem}
Once we know that solutions to a nonlinear system exist, we can sometimes bound
them.
\begin{theorem}[Bellman-Gronwall Lemma]
	Suppose $\lambda\in\R$ is a constant and $\mu:[a,b]\to\R$ is continuous and
	non-negative, then for a continuous function $y:[a, b]\to\R$ \[
		y(t) \leq \lambda + \int_a^t \mu(\tau)y(\tau)d\tau \implies y(t) \leq
		\lambda \text{exp}\left(\int_a^t\mu(\tau)d\tau\right)
	\]
	\label{thm:bellman-gronwall}
\end{theorem}
Another thing we might want to do is understand how the non-linear system reacts
to changes in the initial condition.
\begin{theorem}
	Suppose the system $\diff{\bs{x}}{t} = f(\bs{x}, t),\ \bs{x}(t_0) = \bs{x}_0$
	satisfies the conditions of global uniqueness and existence. Fix $T\in[t_0,
	\infty]$ and suppose $\bs{x}(\cdot)$ and $\bs{z}(\cdot)$  are two solutions
	satisfying $\diff{\bs{x}}{t} = f(\bs{x}, t), \bs{x}(t_0) = \bs{x}_0$ and
	$\diff{\bs{z}}{t} = f(\bs{z}(t), t),\ \bs{z}(t_0)=\bs{z}_0$, then $\forall
	\epsilon > 0, \exists \delta > 0$ such that \[
		\|\bs{x}_0 - \bs{z}_0\| < \delta \implies \|\bs{x} - \bs{z}\|_{\infty} <
		\epsilon.
	\]
	\label{thm:continuous-dependence-on-ic}
\end{theorem}
\Cref{thm:continuous-dependence-on-ic} is best understood by defining a function
$\Psi:\R^n \to C_n[t_0, t]$ where $\Psi(\bs{x}_0)(t)$ returns the solution to
the system given the initial condition. If the conditions of
\Cref{thm:continuous-dependence-on-ic} are satisfied, then the function $\Psi$
will be continuous.

\subsection{Planar Dynamical Systems}
Planar dynamical systems are those with 2 state variables.
Suppose we linearize the system $\diff[]{\bs{x}}{t} = f(\bs{x})$ at an equilibrium point.
\[
	\diff[]{\bs{x}}{t} = D_f|_{\bs{x} = \bs{x_0}}\bs{x} 
\]
Depending on the eigenvalues of $D_f$, the Jacobian, we get several cases for
how this linear system behaves. We'll let $z_1$ and $z_2$ be the eigenbasis of
the \textit{phase space}.
\begin{enumerate}
	\item The eigenvalues are real, yielding solutions $z_1 = z_1(0)e^{\lambda_1
		t}, z_2 = z_2(0)e^{\lambda_2 t}$. If we eliminate the time variable, we can
		plot the trajectories of the system.
		\[
			\frac{z_1}{z_1(0)} = \left(\frac{z_2}{z_2(0)}\right)^{\frac{\lambda_1}{\lambda_2}}
		\]
		\begin{enumerate}
			\item When $\lambda_1, \lambda_2 < 0$, all trajectories converge to the origin, so we call this a \textbf{stable node}.
			\item When $\lambda_1, \lambda_2 > 0$, all trajectories blow up, so we call this an \textbf{unstable node}.
			\item When $\lambda_1 < 0 < \lambda_2$, the trajectories will converge to
				the origin along the axis corresponding to $\lambda_1$ and diverge along
				the axis corresponding to $\lambda_2$, so we call this a \textbf{saddle node}.
		\end{enumerate}
	\item There is a single repeated eigenvalue with one eigenvector. As before,
		we can eliminate the time variable and plot the trajectories on the $z_1$,
		$z_2$ axes.
		\begin{enumerate}
			\item When $\lambda < 0$, the trajetories will converge to the origin, so
				we call it an \textbf{improper stable node}
			\item When $\lambda > 0$, the trajetories will diverge from the origin, so
				we call it an \textbf{improper unstable node}
		\end{enumerate}
	\item When there is a complex pair of eigenvalues, the linear system will have
		oscillatory behavior. The Real Jordan form of $D_f$ will look like \[
			D_f = \begin{bmatrix} \alpha & \beta \\ -\beta & \alpha \end{bmatrix}.
		\]
		The parameter $\beta$ will determine the direction of the trajectories
		(clockwise if positive).
		\begin{enumerate}
			\item When $\alpha < 0$, the trajectories will spiral towards the origin,
				so we call it a \textbf{stable focus}.
			\item When $\alpha = 0$, the trajectories will remain at a constant radius
				from the origin, so we call it a \textbf{center}.
			\item When $\alpha > 0$, the trajectories will spiral away from the
				origin, so we call it an \textbf{unstable focus}.
		\end{enumerate}
\end{enumerate}
It turns out that understanding the linear dynamics at equilibrium points can be helpful in
understanding the nonlinear dynamics near equilibrium points.
\begin{theorem}[Hartman-Grobman Theorem]
	If the linearization of a planar dynamical system $\diff{\bs{x}}{t} =
	f(\bs{x})$ at an equilibrium point $\bs{x_0}$ has no zero or purely imaginary eigenvalues, then there exists a
	homeomorphism from a neighborhood $U$ of $x_0$ into $\R^2$ which takes
	trajectories of the nonlinear system and maps them onto the linearization
	where $h(\bs{x_0}) = 0$, and the homeomorphism can be chosen to preserve the
	parameterization by time.
	\label{thm:hartman-grobman}
\end{theorem}
\Cref{thm:hartman-grobman} essentially says that the linear dynamics predict the
nonlinear dynamics around equilibria, but only for a neighborhood around the
equilibrium point. Outisde of this neighborhood, the linearization may be very
wrong.

Non-linear systems can also have periodic solutions.
\begin{definition}
	A closed orbit $\gamma$ is a trajectory of the system such that $\gamma(0) =
	\gamma(T)$ for finite $T$.
	\label{defn:closed-orbit}
\end{definition}

Suppose that we have a simply connected region $D$ (meaning $D$ cannot be
contracted to a point) and we want to know if it contains a closed orbit.
\begin{theorem}[Bendixon's Theorem]
	If $\divergence(f)$ is not identically zero in a sub-region of $D$ and does not
	change sign in $D$, then $D$ contains no closed orbits.
	\label{thm:bendixons}
\end{theorem}
\Cref{thm:bendixons} lets us rule out closed orbits from regions of
$\R^2$.
\begin{definition}
	A region $M \subset \R^2$ is positively invariant for a trajectory
	$\phi_t(\bs{x})$ if $\forall x\in M, \forall t \geq 0, \phi_t(\bs{x}) \in M$.
	\label{defn:positive-invariance}
\end{definition}
A positively invariant set essentially means that once a trajectory enters the
set, it cannot leave. That means all of the vector field lines must point inside
the set.
If we have a positively invariant region, then we can determine whether it
contains closed orbits.
\begin{theorem}[Poincare-Bendixson Theorem]
	If $M$ is a compact, positively invariant set for the flow $\phi_t(\bs{x})$,
	then if $M$ contains no equilibrium points, then $M$ has a limit cycle.
	\label{thm:poincare-bendixson}
\end{theorem}
\section{Stability of Nonlinear Systems}
The equilibria of a system can tell us a great deal about the stability of the
system. For nonlinear systems, stability is a property of the equilibrium
points, and to be stable is to converge to or stay equilibrium.
\begin{definition}
	An equilibrium point $\bs{x}_e\in \R$ is a stable equilibrium point in the
	sense of Lyapunov if and only if $\forall \epsilon > 0,\exists \delta(t_0,
	\epsilon)$ such that \[
		\forall t \geq t_0,\ \|\bs{x}_0 - \bs{x}_e\| < \delta(t_0, \epsilon)
		\implies \|\bs{x}(t) - \bs{x}_e\| < \epsilon
	\]
	\label{defn:stability}
\end{definition}
Lyapunov Stability essentially says that a finite deviation in the initial
condition from equilibrium means the resulting trajectory of the system stay close to
equilibrium. Notice that this definition is nearly identical to
\cref{thm:continuous-dependence-on-ic}. That means stability of an equilibrium
point is the same as saying the function which returns the solution to a system
given its initial condition is continuous at the equilibrium point.
\begin{definition}
	An equilibrium point $\bs{x}_e\in \R$ is an uniformly stable equilibrium point in the
	sense of Lyapunov if and only if $\forall \epsilon > 0,\exists \delta(
	\epsilon)$ such that \[
		\forall t \geq t_0,\ \|\bs{x}_0 - \bs{x}_e\| < \delta(\epsilon)
		\implies \|\bs{x}(t) - \bs{x}_e\| < \epsilon
	\]
	\label{defn:uniformly-stable}
\end{definition}
Uniform stability means that the $\delta$ can be chosen independently of the
time the system starts at.
Both stability and uniform stability do not imply convergence to the equilibrium
point. They only guarantee the solution stays within a particular norm ball.
Stricter notions of stabilty add this idea in.
\begin{definition}
	An equilibrium point $\bs{x}_e$ is attractive if $\forall t_0 > 0,\ \exists
	c(t_0)$ such that \[
		\bs{x}(t_0) \in B_c(\bs{x}_e) \implies \lim_{t\to\infty} \|\bs{x}(t, t_0,
		\bs{x}_0) - \bs{x}_e\| = 0
	\]
	\label{defn:attractivity}
\end{definition}
Attractive equilibria guarantee that trajectories beginning from initial
conditions inside of a ball will converge to the equilibrium. However,
attractivity does not imply stability since the trajectory could go arbitarily
far from the equilibrium so long as it eventually returns.
\begin{definition}
	An equilibrium point $\bs{x}_e$ is asymptotically stable if $\bs{x}_e$ is
	stable in the sense of Lyapunov and attractive.
	\label{defn:asymptotic-stability}
\end{definition}
Asymptotic stability fixes the problem of attractivity where trajectories could
go far from the equilibrium, and it fixes the problem with stability where the
trajectory may not converge to equilibrium. It means that trajectories starting
in a ball around equilibrium will converge to equilibrium without leaving that
ball. Because the constant for attractivity may depend on time, defining
uniform asymptotic stability requires some modifications to the idea of
attractivity.
\begin{definition}
	An equilibrium point is uniformly asympototically stable if $\bs{x}_e$ is
	uniformly stable in the sense of Lyapunov, and $\exists c$ and
	$\gamma:\R_+\times\R^n\to\R_+$ such that \[
		\forall \bs{x}_0\in B_c(\bs{x}_e),\ \lim_{\tau\to\infty}\gamma(\tau,
		\bs{x}_0) = 0, \qquad \forall t\geq t_0,\ \|\bs{x}(t, t_0, \bs{x}_0) - \bs{x}_e\| \leq
		\gamma(t-t_0, \bs{x}_0)
	\]
	\label{defn:uniform-asymptotic-stability}
\end{definition}
The existence of the $\gamma$ function helps guarantee that the rate of
converges to equilibrium does not depend on $t_0$ since the function $\gamma$ is
independent of $t_0$.
Suppose that the $\gamma$ is an exponential function. Then solutions to the
system will converge to the equilibrium exponentially fast.
\begin{definition}
	An equilibrium point $\bs{x}_e$ is locally exponentially stable if $\exists
	h,m,\alpha$
	such that \[
		\forall \bs{x}_0\in B_h(\bs{x}_e),\ \|\bs{x}(t, t_0, \bs{x}_0) -
		\bs{x}_e\| \leq me^{-\alpha(t - t_0)}\|\bs{x}(t) - \bs{x}_e\|
	\]
	\label{defn:exponential-stability}
\end{definition}
\Cref{defn:stability,defn:uniformly-stable,defn:asymptotic-stability,defn:uniform-asymptotic-stability,defn:exponential-stability}
are all local definitions because the only need to hold for $\bs{x}_0$ inside a
ball around the equilibrium. If they hold $\forall \bs{x}_0\in\R^n$, then they
become global properties.

Just as we can define stability, we can also define instability.
\begin{definition}
	An equilibrium point $\bs{x}_e$ is unstable in the sense of Lyapunov if
	$\exists \epsilon > 0, \forall delta > 0$ such that \[
		\exists \bs{x}_0\in B_\delta(\bs{x}_e) \implies \exists T\geq t_0, x(T, t_0,
		\bs{x}_0) \not\in B_\epsilon(\bs{x}_e)
	\]
	\label{defn:unstable}
\end{definition}
Instability means that for any $\delta-$ball, we can find an $\epsilon-$ball for
which there is at least one initial condition whose corresponding trajectory
leaves the $\epsilon-$ball.
\subsection{Lyapunov Functions}
In order to prove different types of stability, we will construct functions
which have particular properties around equilibrium points of the system. The
properties of these functions will help determine what type of stable the
equilibrium point is.
\begin{definition}
	A class $\mathcal{K}$ function is a function $\alpha: \R_+ \to \R_+$ such that
	$\alpha(0) = 0$ and $\alpha(s)$ is strictly monotonically increasing in $s$.
	\label{defn:class-k-function}
\end{definition}
A subset of the class $\mathcal{K}$ functions grow unbounded as the argument
approaches infinity.
\begin{definition}
	A class $\mathcal{KR}$ function is a class $\mathcal{K}$ function $\alpha$
	where $\lim_{s\to\infty}\alpha(s) = s$.
	\label{defn:class-kr-function}
\end{definition}
Class $\mathcal{KR}$ functions are ``radially unbounded''.
We can use class $\mathcal{K}$ and class $\mathcal{KR}$ to bound ``energy-like''
functions called \textbf{Lyapunov Functions}.
\begin{definition}
	A function $V(\bs{x}, t): \R^n \times \R_+ \to \R$ is locally positive
	definite (LPDF) on a set $G\subset \R^n$ containing $\bs{x}_e$ if $\exists
	\alpha \in \mathcal{K}$ such that \[
		V(\bs{x}, t) \geq \alpha(\|\bs{x} - \bs{x}_e\|)
	\]
	\label{defn:lpdf}
\end{definition}
LPDF functions are locally ``energy-like'' in the sense that the equilibrium
point is assigned the lowest ``energy'' value, and the larger the deviation from
the equilibrium, the higher the value of the ``energy''.
\begin{definition}
	A function $V(\bs{x}, t): \R^n \times \R_+ \to \R$ is positive
	definite (PDF) if $\exists
	\alpha \in \mathcal{KR}$ such that \[
		\forall \bs{x}\in\R^n,\ V(\bs{x}, t) \geq \alpha(\|\bs{x} - \bs{x}_e\|)
	\]
	\label{defn:pdf}
\end{definition}
Positive definite functions act like ``energy functions'' everywhere in $\R^n$.
\begin{definition}
	A function $V(\bs{x}, t): \R^n \times \R_+ \to \R$ is decrescent
	if $\exists
	\alpha \in \mathcal{K}$ such that \[
		\forall \bs{x}\in B_h(\bs{x}_e),\ V(\bs{x}, t) \leq \beta(\|\bs{x} - \bs{x}_e\|)
	\]
	\label{defn:decrescent}
\end{definition}
Descresence means that for a ball around the equilibrium, we can upper bound the
growth of the energy.

Note that we can assume $\bs{x}_e = 0$ without loss of generality for
\cref{defn:lpdf,defn:pdf,defn:decrescent} since for a given system, we can always define a linear
change of variables that shifts the equilibrium point to the origin.

\subsection{Proving Stability}
To prove the stability of an equilibrium point for a given nonlinear system, we
will construct a Lyapunov function and determine stability from the properties
of the Lyapunov functions which we can find.
\begin{definition}
	The Lie derivative of a function $V(\bs{x}, t)$ is given by \[
		\diff{V}{t} = \frac{\partial V}{\partial t}  +
		\frac{\partial V}{\partial \bs{x}}f(\bs{x}, t).
	\]
	\label{defn:lie-derivative}
\end{definition}
The Lie derivative is essentially the directional derivative along the
trajectories of the system.
Given properties of $V$ and $\diff{V}{t}$, we can use the \textbf{Lyapunov
Stability Theorems} to prove the stability of equilibria.
\begin{theorem}
	If $\exists V(\bs{x}, t)$ such that $V$ is LPDF and the Lie Derivative
	$-\diff{V}{t} \geq 0$ locally, then $\bs{x}_e$ is stable in the sense of
	Lyapunov.
	\label{thm:lyapunov-sisl}
\end{theorem}
\begin{theorem}
	If $\exists V(\bs{x}, t)$ such that $V$ is LPDF and decrescent, and the Lie Derivative
	$-\diff{V}{t} \geq 0$ locally, then $\bs{x}_e$ is uniformly stable in the sense of
	Lyapunov.
	\label{thm:lyapunov-uniformly-sisl}
\end{theorem}
\begin{theorem}
	If $\exists V(\bs{x}, t)$ such that $V$ is LPDF and decrescent, and the Lie Derivative
	$-\diff{V}{t}$ is LPDF, then $\bs{x}_e$ is uniformly asymptotically stable in the sense of
	Lyapunov.
	\label{thm:lyapunov-uniformly-as}
\end{theorem}
\begin{theorem}
	If $\exists V(\bs{x}, t)$ such that $V$ is PDF and decrescent, and the Lie Derivative
	$-\diff{V}{t}$ is LPDF, then $\bs{x}_e$ is globally uniformly asymptotically stable in the sense of
	Lyapunov.
	\label{thm:lyapunov-globally-as}
\end{theorem}
\begin{theorem}
	If $\exists V(\bs{x}, t)$ and $h, \alpha > 0$ such that V is LPDF is
	decrescent, The Lie derivative $-\diff{V}{t}$ is LDPF, and \[
		\forall \bs{x}\in B_h(\bs{x}_e),\ \left\lvert\left\lvert\frac{\partial
		V}{\partial t}\right\rvert\right\rvert \leq \alpha \|\bs{x}-\bs{x}_e\|
	\]
	\label{thm:lyapunov-exponential-stability}
\end{theorem}
The results of
\cref{thm:lyapunov-sisl,thm:lyapunov-uniformly-sisl,thm:lyapunov-uniformly-as,thm:lyapunov-globally-as,thm:lyapunov-exponential-stability}
are summarized in \cref{table:lyapunov-stability}.
\begin{gitbook-image}
\begin{table}[!h]
	\centering
	\begin{tabularx}{\textwidth}{YYY}
		\toprule
		\textbf{Conditions on} $\mathbf{V}$ & \textbf{Conditions on}
		$\mathbf{-\diff{V}{t}}$ & \textbf{Conclusion} \\
		\midrule
		LPDF & $\geq 0$ locally & Stable\\
		\hline
		LPDF, Decrescent & $\geq 0$ locally & Uniformly Stable\\
		\hline
		LPDF, Decrescent & LPDF & Uniformly, Asymptotically Stable\\
		\hline
		LPDF, Decrescent & LDPF, $\exists \alpha > 0$ such that $\left\lvert\left\lvert
		\diff{V}{t}\right\rvert\right\rvert \leq \alpha \|\bs{x} - \bs{x}_e\|$ &
		Exponentially Stable\\
		\hline
		PDF, Decrescent & PDF & Globally, Uniformly, Asymptotically Stable\\
		\bottomrule
	\end{tabularx}
	\caption{Summary of Lyapunov Stability Theorems}
	\label{table:lyapunov-stability}
\end{table}
\end{gitbook-image}
Going down the rows of \cref{table:lyapunov-stability} lead to increasingly
stricter forms of stability. Descresence appears to add uniformity to the
stability, while $-\diff{V}{t}$ being LPDF adds asymptotic convergence. However,
these conditions are only sufficient, meaning if we cannot find a suitable $V$,
that does not mean that an equilibrium point is not stable.

One very common case where it can be difficult to find appropriate Lyapunov
functions is in proving asymptotic stability since it can be hard to find $V$
such that $-\diff{V}{t}$ is LPDF. In the case of autonomous systems, we can
still prove asymptotic stability without such a $V$.
\begin{theorem}[LaSalle's Invariance Principle]
	Consider a smooth function $V:\R^n\to\R$ with bounded sub-level sets $\Omega_c
	= \left\{\bs{x} | V(\bs{x}) \leq c \right\}$ and $\forall \bs{x}\in \Omega_c$, the Lie
	derivative $-\diff{V}{t} \leq 0$. Define $S = \left\{\bs{x}|\diff{V}{t} = 0\right\}$ and let
		$M$ be the largest invariant set in $S$, then \[
			\forall \bs{x}_0\in \Omega_c,\ \bs{x}(t, t_0, x_0) \to M \text{ as } t\to
			\infty.
		\]
	\label{thm:la-salles}
\end{theorem}
LaSalle's theorem helps prove general convergence to an invariant set. Since $V$
is always decreasing in the sub-level set $\Omega_c$, trajectories starting in
$\Omega_c$ must eventually reach $S$. At some point, they will reach the set $M$
in $S$, and then they will stay there. Thus if the set $M$ is only the
equilibrium point, or a set of equilibrium points, then we can show that the
system trajectories asymptotically converges to this equilibrium or set of
equilibria. Moreover, if $V(\bs{x})$ is PDF, and $\forall \bs{x}\in\mathbb{R}^n,
\diff{V}{t} \leq 0$, then we can show global asymptotic stability as well.

LaSalle's theorem can be generalized to non-autonomous systems as well, but it
is slightly more complicated since the set $S$ may change over time.

\subsubsection{Indirect Method of Lyapunov}
It turns out that we can also prove the stability of systems by looking at the
linearization around the equilibrium. Without loss of generality, suppose
$\bs{x}_e = 0$. The linearization at the equilibrium is given by \[
	\diff{\bs{x}}{t} = f(x,t) = f(0, t) + \frac{\partial f}{\partial
	\bs{x}}|_{\bs{x} = 0}\bs{x} + f_1(\bs{x},t) \approx A(t)\bs{x}.
\]
The function $f_1(\bs{x}, t)$ is the higher-order terms of the linearization.
The linearization is a time-varying system.
Consider the time-varying linear system
\[
	\diff{\bs{x}}{t} = A(t)\bs{x},\ \bs{x}(t_0) = \bs{x}_0.
\]
\begin{definition}
	The state transition matrix $\Phi(t, t_0)$ of a time-varying linear system is
	a matrix satisfying \[
		\bs{x}(t) = \Phi(t, t_0)\bs{x}_0,\ \diff{\Phi}{t} = A(t)\Phi(t, t_0),\
		\Phi(t_0, t_0) = I
	\]
	\label{defn:state-transition-matrix}
\end{definition}
The state transition matrix is useful in determining properties of the system.
\begin{enumerate}
	\item $\sup_{t\geq t_0} \|\Phi(t, t_0)\| = m(t_0) < \infty \implies$ the system
		is stable at the origin at $t_0$.
	\item $\sup_{t_0\geq 0}\sup_{t\geq t_0} \|\Phi(t, t_0)\| = m < \infty \implies$ the system
		is uniformly stable at the origin at $t_0$.
	\item $\lim_{t\to\infty}\|\Phi(t, t_0)\| = 0 \implies$ the system is
		asymptotically stable.
	\item $\forall t_0,\epsilon>0,\exists T$ such that $\forall t\geq t_0 + T,\ \|\Phi(t, t_0)\| <
		\epsilon \implies$ the system is uniformly asymptotically stable.
	\item $\|\Phi(t, t_0)\| \leq Me^{-\lambda(t-t_0)} \implies$ exponential
		stability.
\end{enumerate}
If the system was Time-Invariant, then the system would be stable so long as the
eigenvalues of $A$ were in the open left-half of the complex plane. In fact, we
could use $A$ to construct positive definite matrices.
\begin{theorem}[Lyapunov Lemma]
	For a matrix $A\in \R^{n\times n}$, its eigenvalues $\lambda_i$ satisfy
	$\Re(\lambda_i) < 0$ if and only if $\forall Q \succ 0$, there exists
	a solution $P\succ 0$ to the equation \[
		A^TP + PA = -Q.
	\]
	\label{thm:lyapunov-lemma}
\end{theorem}
In general, we can use the \textbf{Lyapunov Equation} to count how many
eigenvalues of $A$ are stable.
\begin{theorem}[Tausskey Lemma]
	For $A\in\R^{n\times n}$ and given $Q \succ 0$, if there are no eigenvalues on
	the $j\omega$ axis, then the solution $P$ to $A^TP + PA = -Q$ has as many
	positive eigenvalues as $A$ has eigenvalues in the complex left half plane.
	\label{thm:tausskey-lemma}
\end{theorem}
The Lyapunov Lemma has extensions to the time-varying case.
\begin{theorem}[Time-Varying Lyapunov Lemma]
	If $A(\cdot)$ is bounded and for some $Q(t) \succeq \alpha I$, the solution
	$P(t)$ to $A(t)^TP(t) + P(t)A(t) = -Q(t)$ is bounded, then the origin is a
	asymptotically stable equilibrium point.
	\label{thm:tv-lyapuynov-lemma}
\end{theorem}
It turns out that uniform asymptotic stability of the linearization of a system
corresponds to uniform, asymptotic stability of the nonlinear system.
\begin{theorem}[Indirect Theorem of Lyapunov]
	For a nonlinear system whose higher-order terms of the linearization are given
	by $f(\bs{x},t)$, if \[
		\lim_{\|\bs{x}\|\to 0}\sup_{t\geq 0} \frac{\|f_1(\bs{x},t)\|}{\|\bs{x}\|} =
		0
	\]
	and if $\bs{x}_e$ is a uniformly asymptotic stable equilibrium point of
	$\diff{\bs{z}}{t}=A(t)\bs{z}$ where $A(t)$ is the Jacobian at the $\bs{x}_e$,
	then $\bs{x}_e$ is a uniformly asymptotic stable
	equilibrium point of $\diff{\bs{x}}{t} = f(\bs{x},t)$
	\label{thm:indirect-lyapunov}
\end{theorem}
\subsection{Proving Instability}
\begin{theorem}
	An equilibrium point $\bs{x}_e$ is unstable in the sense of Lyapunov if
	$\exists V(\bs{x},t)$ which is decrescent, the Lie derivative $\diff{V}{t}$ is
	LPDF, $V(\bs{x}_e, t)$, and $\exists \bs{x}$ in the neighborhood of $\bs{x}_e$
	such that $V(\bs{x}_0, t) > 0$.
	\label{thm:lyapunov-instability}
\end{theorem}
\end{document}

